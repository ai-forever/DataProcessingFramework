{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlavaNextConfig, LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "from DPF import S3Connector, DatasetReader, ShardsDatasetConfig\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "from typing import Any\n",
    "from py3langid.langid import MODEL_FILE, LanguageIdentifier\n",
    "from DPF.filters.images.img_filter import ImageFilter\n",
    "from DPF.types import ModalityToDataMapping\n",
    "\n",
    "class Llava34b_Filter(ImageFilter):\n",
    "    \"\"\"\n",
    "    The filter implements a description of the images supplied to the input.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str = 'llava-hf/llava-v1.6-34b-hf',\n",
    "        workers: int = 16,\n",
    "        batch_size: int = 16,\n",
    "        device: str = \"cuda:0\",\n",
    "        pbar: bool = True,\n",
    "        _pbar_position: int = 0\n",
    "    ):\n",
    "        super().__init__(pbar, _pbar_position)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = workers\n",
    "        self.device = device\n",
    "        self.prompt = \"<|im_start|>system\\nAnswer the questions.<|im_end|><|im_start|>user\\n<image>\\nDescribe this image and its style in a very detailed manner<|im_end|><|im_start|>assistant\\n\"\n",
    "        \n",
    "        self.processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-34b-hf\")\n",
    "        \n",
    "        self.model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "        \"llava-hf/llava-v1.6-34b-hf\",\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attention_2=True,\n",
    "        device_map=self.device)\n",
    "\n",
    "    @property\n",
    "    def result_columns(self) -> list[str]:\n",
    "        return [\"llava34b_caption\"]\n",
    "\n",
    "    @property\n",
    "    def dataloader_kwargs(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"num_workers\": self.num_workers,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"drop_last\": False,\n",
    "        }\n",
    "\n",
    "    def preprocess_data(\n",
    "        self,\n",
    "        modality2data: ModalityToDataMapping,\n",
    "        metadata: dict[str, Any]\n",
    "    ) -> Any:\n",
    "        key = metadata[self.key_column]\n",
    "        pil_img = read_image_rgb_from_bytes(modality2data['image']).convert('RGB')\n",
    "        img_tensor = self.image_processor.preprocess(pil_img, return_tensors='pt')['pixel_values'].half()\n",
    "        return key, img_tensor\n",
    "\n",
    "    def process_batch(self, batch: list[Any]) -> dict[str, list[Any]]:\n",
    "        df_batch_labels = self._get_dict_from_schema()\n",
    "\n",
    "        keys, image_tensors = list(zip(*batch))\n",
    "        image_tensors = default_collate(image_tensors).to(self.device)  # type: ignore\n",
    "\n",
    "        input_ids_batch = self.input_ids.repeat_interleave(image_tensors.shape[0], 0).to(self.device)  # type: ignore\n",
    "        with torch.inference_mode():\n",
    "            output_ids = self.model.generate(\n",
    "                input_ids_batch, images=image_tensors, do_sample=True, temperature=0.2, top_p=0.7,\n",
    "                max_new_tokens=512, use_cache=True, stopping_criteria=[self.stopping_criteria]\n",
    "            )\n",
    "\n",
    "        all_outputs = []\n",
    "        for i in range(output_ids.shape[0]):\n",
    "            output = self.tokenizer.decode(output_ids[i, self.input_ids.shape[1]:]).strip().split('</s>')[0]\n",
    "            all_outputs.append(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-env3.11]",
   "language": "python",
   "name": "conda-env-.mlspace-env3.11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
